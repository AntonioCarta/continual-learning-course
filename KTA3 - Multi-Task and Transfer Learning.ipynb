{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15883cac",
   "metadata": {},
   "source": [
    "# Multi-Task and Transfer Learning\n",
    "\n",
    "you can take the code of the model's architecture and training loop from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install avalanche-lib==0.5.0 pytorchcv==0.0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8387b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import avalanche\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d59804",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "image classification datasets with 32x32 images\n",
    "\n",
    "- CIFAR10: 10 classes\n",
    "- CIFAR100: 100 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5b50d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mavalanche\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SplitCIFAR10, SplitCIFAR100\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mavalanche\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m benchmark_with_validation_stream\n\u001b[1;32m----> 4\u001b[0m task0 \u001b[38;5;241m=\u001b[39m benchmark_with_validation_stream(\u001b[43mSplitCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_experiences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, validation_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m task1 \u001b[38;5;241m=\u001b[39m benchmark_with_validation_stream(SplitCIFAR100(n_experiences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), validation_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\site-packages\\avalanche\\benchmarks\\classic\\ccifar10.py:131\u001b[0m, in \u001b[0;36mSplitCIFAR10\u001b[1;34m(n_experiences, first_exp_with_half_classes, return_task_id, seed, fixed_class_order, shuffle, class_ids_from_zero_in_each_exp, class_ids_from_zero_from_first_exp, train_transform, eval_transform, dataset_root)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSplitCIFAR10\u001b[39m(\n\u001b[0;32m     41\u001b[0m     n_experiences: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     dataset_root: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NCScenario:\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    Creates a CL benchmark using the CIFAR10 dataset.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    :returns: A properly initialized :class:`NCScenario` instance.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     cifar_train, cifar_test \u001b[38;5;241m=\u001b[39m \u001b[43mget_cifar10_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nc_benchmark(\n\u001b[0;32m    134\u001b[0m         train_dataset\u001b[38;5;241m=\u001b[39mcifar_train,\n\u001b[0;32m    135\u001b[0m         test_dataset\u001b[38;5;241m=\u001b[39mcifar_test,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m         eval_transform\u001b[38;5;241m=\u001b[39meval_transform,\n\u001b[0;32m    146\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\site-packages\\avalanche\\benchmarks\\datasets\\external_datasets\\cifar.py:12\u001b[0m, in \u001b[0;36mget_cifar10_dataset\u001b[1;34m(dataset_root)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     dataset_root \u001b[38;5;241m=\u001b[39m default_dataset_location(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m test_set \u001b[38;5;241m=\u001b[39m CIFAR10(\u001b[38;5;28mstr\u001b[39m(dataset_root), train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_set, test_set\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\site-packages\\torchvision\\datasets\\cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\site-packages\\torchvision\\datasets\\cifar.py:139\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\site-packages\\torchvision\\datasets\\utils.py:378\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    376\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 378\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\site-packages\\torchvision\\datasets\\utils.py:119\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    116\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m    117\u001b[0m fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, filename)\n\u001b[1;32m--> 119\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# check if file is already present locally\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_integrity(fpath, md5):\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\w-32\\mambaforge\\envs\\791aa\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\'"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import SplitCIFAR10, SplitCIFAR100\n",
    "from avalanche.benchmarks import benchmark_with_validation_stream\n",
    "\n",
    "task0 = benchmark_with_validation_stream(SplitCIFAR10(n_experiences=1), validation_size=0.3, shuffle=True)\n",
    "task1 = benchmark_with_validation_stream(SplitCIFAR100(n_experiences=1), validation_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae14b46",
   "metadata": {},
   "source": [
    "Task 0 (CIFAR10) returns triplets `<x, y, 0>`, while Task 1 (CIFAR100) returns `<x, y, 1>`. You can use task labels in your code to select task-aware modules (e.g. a different classification head for each task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ffe3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from avalanche.benchmarks.utils import make_classification_dataset\n",
    "\n",
    "# task 0 with task label 0\n",
    "t0_train_data = task0.train_stream[0].dataset\n",
    "t0_valid_data = task0.valid_stream[0].dataset\n",
    "t0_test_data = task0.test_stream[0].dataset\n",
    "\n",
    "# task 1 with task label 1\n",
    "t1_train_data = task1.train_stream[0].dataset\n",
    "t1_train_data = t1_train_data.update_data_attribute(\"targets_task_labels\", [1 for el in range(len(t1_train_data))])\n",
    "t1_valid_data = task1.valid_stream[0].dataset\n",
    "t1_valid_data = t1_valid_data.update_data_attribute(\"targets_task_labels\", [1 for el in range(len(t1_valid_data))])\n",
    "t1_test_data = task1.test_stream[0].dataset\n",
    "t1_test_data = t1_test_data.update_data_attribute(\"targets_task_labels\", [1 for el in range(len(t1_test_data))])\n",
    "\n",
    "# check task labels\n",
    "t0_train_data[0][2], t1_train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b0544",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "Implement the \"Simple Transfer Learning\" recipe that we have seen in the previous lecture.\n",
    "- pretrain on CIFAR10\n",
    "- finetune on CIFAR100\n",
    "\n",
    "Is it better than training from scratch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09adfb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89cab2d1",
   "metadata": {},
   "source": [
    "# Multi-Task Learning\n",
    "\n",
    "Train the two tasks together with a multi-head architecture\n",
    "- modify the ResNet18 with a multi-head classifier\n",
    "- modify the training loop to jointly sample from both tasks\n",
    "\n",
    "is it better than learning each task independently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b7e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b0210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "791aa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
