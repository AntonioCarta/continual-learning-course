{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a79a27e",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch\n",
    "\n",
    "we will use:\n",
    "- PyTorch for the deep learning tools (modules, optimizers, losses, ...)\n",
    "- torchvision for the computer vision architectures and datasets\n",
    "- Avalanche for the multi-task streams of datasets and dynamic architectures (and later for incremental learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58f322",
   "metadata": {},
   "source": [
    "install dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79ac545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting avalanche-lib==0.5.0\n",
      "  Using cached avalanche_lib-0.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from avalanche-lib==0.5.0) (4.9.0)\n",
      "Requirement already satisfied: psutil in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from avalanche-lib==0.5.0) (5.9.8)\n",
      "Collecting gputil (from avalanche-lib==0.5.0)\n",
      "  Using cached GPUtil-1.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from avalanche-lib==0.5.0) (1.4.1.post1)\n",
      "Requirement already satisfied: matplotlib in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from avalanche-lib==0.5.0) (3.8.3)\n",
      "Requirement already satisfied: numpy in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from avalanche-lib==0.5.0) (1.26.4)\n",
      "Collecting pytorchcv (from avalanche-lib==0.5.0)\n",
      "  Using cached pytorchcv-0.0.67-py2.py3-none-any.whl.metadata (133 kB)\n",
      "Collecting wandb (from avalanche-lib==0.5.0)\n",
      "  Downloading wandb-0.16.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tensorboard>=1.15 (from avalanche-lib==0.5.0)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tqdm (from avalanche-lib==0.5.0)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: torch in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from avalanche-lib==0.5.0) (2.2.0)\n",
      "Collecting torchvision (from avalanche-lib==0.5.0)\n",
      "  Downloading torchvision-0.17.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchmetrics (from avalanche-lib==0.5.0)\n",
      "  Using cached torchmetrics-1.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting gdown (from avalanche-lib==0.5.0)\n",
      "  Using cached gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting qpsolvers[open_source_solvers] (from avalanche-lib==0.5.0)\n",
      "  Using cached qpsolvers-4.3.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting dill (from avalanche-lib==0.5.0)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from avalanche-lib==0.5.0) (23.2)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=1.15->avalanche-lib==0.5.0)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=1.15->avalanche-lib==0.5.0)\n",
      "  Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=1.15->avalanche-lib==0.5.0)\n",
      "  Using cached Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=1.15->avalanche-lib==0.5.0)\n",
      "  Downloading protobuf-5.26.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5.0) (69.0.3)\n",
      "Requirement already satisfied: six>1.9 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5.0) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=1.15->avalanche-lib==0.5.0)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=1.15->avalanche-lib==0.5.0)\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from gdown->avalanche-lib==0.5.0) (4.12.3)\n",
      "Requirement already satisfied: filelock in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from gdown->avalanche-lib==0.5.0) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from gdown->avalanche-lib==0.5.0) (2.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from matplotlib->avalanche-lib==0.5.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from matplotlib->avalanche-lib==0.5.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from matplotlib->avalanche-lib==0.5.0) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from matplotlib->avalanche-lib==0.5.0) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from matplotlib->avalanche-lib==0.5.0) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from matplotlib->avalanche-lib==0.5.0) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from matplotlib->avalanche-lib==0.5.0) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from scikit-learn->avalanche-lib==0.5.0) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from scikit-learn->avalanche-lib==0.5.0) (3.3.0)\n",
      "Requirement already satisfied: sympy in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from torch->avalanche-lib==0.5.0) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from torch->avalanche-lib==0.5.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from torch->avalanche-lib==0.5.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from torch->avalanche-lib==0.5.0) (2024.2.0)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics->avalanche-lib==0.5.0)\n",
      "  Using cached lightning_utilities-0.10.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting torch (from avalanche-lib==0.5.0)\n",
      "  Downloading torch-2.2.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: colorama in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from tqdm->avalanche-lib==0.5.0) (0.4.6)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb->avalanche-lib==0.5.0)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->avalanche-lib==0.5.0)\n",
      "  Using cached GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->avalanche-lib==0.5.0)\n",
      "  Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->avalanche-lib==0.5.0)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from wandb->avalanche-lib==0.5.0) (6.0.1)\n",
      "Collecting setproctitle (from wandb->avalanche-lib==0.5.0)\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb->avalanche-lib==0.5.0)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=1.15->avalanche-lib==0.5.0)\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.5.0)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from requests[socks]->gdown->avalanche-lib==0.5.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from requests[socks]->gdown->avalanche-lib==0.5.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from requests[socks]->gdown->avalanche-lib==0.5.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from requests[socks]->gdown->avalanche-lib==0.5.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=1.15->avalanche-lib==0.5.0) (2.1.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from beautifulsoup4->gdown->avalanche-lib==0.5.0) (2.5)\n",
      "Collecting clarabel>=0.4.1 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading clarabel-0.7.1-cp37-abi3-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting cvxopt>=1.2.6 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading cvxopt-1.3.2-cp311-cp311-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting daqp>=0.5.1 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading daqp-0.5.1-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting ecos>=2.0.8 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading ecos-2.0.13-cp311-cp311-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting highspy>=1.1.2.dev3 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading highspy-1.7.1.dev1-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting osqp>=0.6.2 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading osqp-0.6.5-cp311-cp311-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting piqp>=0.2.2 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading piqp-0.2.4-cp311-cp311-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting proxsuite>=0.2.9 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading proxsuite-0.6.2-0-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting qpalm>=1.2.1 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading qpalm-1.2.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting quadprog>=0.1.11 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading quadprog-0.1.12-cp311-cp311-win_amd64.whl.metadata (1.3 kB)\n",
      "Collecting scs>=3.2.0 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading scs-3.2.4.post1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown->avalanche-lib==0.5.0)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\miniforge\\envs\\791aa\\lib\\site-packages (from sympy->torch->avalanche-lib==0.5.0) (1.3.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.5.0)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting scipy>=1.2.0 (from qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     --------------------------------- ------ 51.2/60.4 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.4/60.4 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting qdldl (from osqp>=0.6.2->qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Downloading qdldl-0.1.7.post0-cp311-cp311-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting cmeel (from proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib==0.5.0)\n",
      "  Using cached cmeel-0.53.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Using cached avalanche_lib-0.5.0-py3-none-any.whl (971 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Using cached pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\n",
      "Using cached torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
      "Downloading torchvision-0.17.1-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.6/1.2 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading torch-2.2.1-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.6/198.6 MB 19.2 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 1.4/198.6 MB 17.2 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 2.1/198.6 MB 16.8 MB/s eta 0:00:12\n",
      "    --------------------------------------- 2.8/198.6 MB 16.3 MB/s eta 0:00:13\n",
      "    --------------------------------------- 3.5/198.6 MB 16.0 MB/s eta 0:00:13\n",
      "    --------------------------------------- 4.3/198.6 MB 16.0 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 5.0/198.6 MB 15.9 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 5.7/198.6 MB 15.8 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 6.4/198.6 MB 15.7 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 7.1/198.6 MB 15.8 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 7.9/198.6 MB 15.7 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 8.6/198.6 MB 15.7 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 9.3/198.6 MB 15.7 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 10.1/198.6 MB 15.7 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 10.8/198.6 MB 15.6 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 11.5/198.6 MB 15.6 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 11.7/198.6 MB 15.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 11.7/198.6 MB 15.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 12.4/198.6 MB 13.9 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 13.3/198.6 MB 14.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 14.9/198.6 MB 14.9 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 15.6/198.6 MB 14.9 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 16.3/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 17.1/198.6 MB 14.9 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 17.8/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 18.5/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 19.3/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 20.0/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 20.7/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 21.5/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 22.2/198.6 MB 17.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 22.9/198.6 MB 16.8 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 23.7/198.6 MB 16.8 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 24.4/198.6 MB 15.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 25.1/198.6 MB 15.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 25.8/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 26.4/198.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 27.2/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 28.0/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 28.6/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 29.4/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 30.1/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 30.9/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 31.6/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 32.3/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.0/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.7/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 34.4/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 35.2/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 35.9/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 36.7/198.6 MB 16.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 37.4/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 38.1/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 38.8/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 39.5/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 40.2/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 41.0/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 41.6/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 42.4/198.6 MB 15.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 43.1/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 43.8/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 44.6/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 45.3/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 45.9/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 46.7/198.6 MB 15.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 47.4/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 48.2/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 48.9/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 49.6/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 50.3/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 51.0/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 51.7/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 52.5/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 53.2/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 53.9/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 54.6/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 55.4/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 56.1/198.6 MB 16.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 56.8/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 57.5/198.6 MB 15.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 58.3/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 59.0/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 59.6/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 60.4/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 61.2/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 61.9/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 62.6/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 63.3/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 64.0/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 64.7/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 65.0/198.6 MB 15.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 65.6/198.6 MB 15.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 66.8/198.6 MB 15.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 67.5/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 68.2/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 68.9/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 69.6/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 70.4/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 71.1/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 71.8/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 72.5/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 73.3/198.6 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 74.0/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 74.7/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 75.4/198.6 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 76.1/198.6 MB 16.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 76.9/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 77.6/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 78.3/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 79.0/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 79.7/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 80.5/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 81.2/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 81.9/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 82.6/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 83.3/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 84.0/198.6 MB 15.2 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 84.8/198.6 MB 15.2 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 85.5/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 86.2/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 86.9/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 87.6/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 88.4/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 89.1/198.6 MB 15.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 89.8/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 90.5/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 91.2/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 91.9/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 92.6/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 93.3/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 94.1/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 94.8/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 95.5/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 96.2/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 96.9/198.6 MB 15.2 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 97.7/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 98.4/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 99.1/198.6 MB 15.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 99.8/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 100.5/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 101.3/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 102.0/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 102.7/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 103.4/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 104.1/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 104.8/198.6 MB 15.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 105.5/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 106.3/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 107.0/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 107.7/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 108.4/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 109.1/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 109.8/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 110.6/198.6 MB 15.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 111.3/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 112.0/198.6 MB 15.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 112.7/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 113.4/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 114.1/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 114.8/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 115.6/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 116.3/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 117.0/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 117.7/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 118.5/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 119.2/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 119.9/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 120.6/198.6 MB 15.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 121.3/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 122.0/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 122.7/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 123.4/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 124.1/198.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 124.9/198.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 125.6/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 126.3/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 127.0/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 127.7/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 128.4/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 129.1/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 129.8/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 130.6/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 131.3/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 132.0/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 132.7/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 133.4/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 134.2/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 134.9/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 135.6/198.6 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 136.4/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 137.1/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 137.8/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 138.5/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 139.3/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 140.0/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 140.7/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 141.4/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 142.1/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 142.8/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 143.6/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 144.1/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 145.0/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 145.7/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 146.4/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 147.1/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 147.8/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 148.6/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 149.3/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 150.0/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 150.7/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 151.4/198.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 152.1/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 152.8/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 153.5/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 154.3/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 155.0/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 155.7/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 156.4/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 157.1/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 157.8/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 158.5/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 159.3/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 160.0/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 160.7/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 161.4/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 162.2/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 162.9/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 163.6/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 164.3/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 165.0/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 165.7/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 166.5/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 167.2/198.6 MB 15.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 167.9/198.6 MB 15.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 168.6/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 169.3/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 169.8/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 170.8/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 171.5/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 172.2/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 172.9/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 173.6/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 174.3/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 175.0/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 175.8/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 176.5/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 177.2/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 177.9/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 178.6/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 179.4/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 180.0/198.6 MB 15.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 180.8/198.6 MB 15.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 181.5/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 182.2/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 182.9/198.6 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 183.7/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 184.4/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 185.1/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 185.8/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 186.5/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 187.2/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 188.0/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 188.7/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 189.4/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 189.9/198.6 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 190.8/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 191.5/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 192.3/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.0/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  193.7/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  194.4/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.2/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.9/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  196.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.3/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.0/198.6 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 198.6/198.6 MB 7.6 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.7/2.2 MB 15.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.2 MB 15.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 12.7 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.7/3.8 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.4/3.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.1/3.8 MB 15.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 15.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.6/3.8 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 13.4 MB/s eta 0:00:00\n",
      "Using cached lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
      "Using cached Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl (263 kB)\n",
      "   ---------------------------------------- 0.0/263.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 263.5/263.5 kB 16.9 MB/s eta 0:00:00\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Using cached qpsolvers-4.3.1-py3-none-any.whl (78 kB)\n",
      "Downloading setproctitle-1.3.3-cp311-cp311-win_amd64.whl (11 kB)\n",
      "Downloading clarabel-0.7.1-cp37-abi3-win_amd64.whl (321 kB)\n",
      "   ---------------------------------------- 0.0/321.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 321.5/321.5 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading cvxopt-1.3.2-cp311-cp311-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.7/12.8 MB 15.7 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.0/12.8 MB 16.7 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.5/12.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.2/12.8 MB 11.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.9/12.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.7/12.8 MB 13.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.2/12.8 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.7/12.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.2/12.8 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.4/12.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.1/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.9/12.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.6/12.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.3/12.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.0/12.8 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.8 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.4/12.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.1/12.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 13.1 MB/s eta 0:00:00\n",
      "Downloading daqp-0.5.1-cp311-cp311-win_amd64.whl (81 kB)\n",
      "   ---------------------------------------- 0.0/81.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 81.3/81.3 kB ? eta 0:00:00\n",
      "Downloading ecos-2.0.13-cp311-cp311-win_amd64.whl (72 kB)\n",
      "   ---------------------------------------- 0.0/72.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 72.0/72.0 kB 3.9 MB/s eta 0:00:00\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading highspy-1.7.1.dev1-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.6/1.7 MB 18.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.7 MB 16.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 18.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 13.8 MB/s eta 0:00:00\n",
      "Downloading osqp-0.6.5-cp311-cp311-win_amd64.whl (293 kB)\n",
      "   ---------------------------------------- 0.0/293.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 293.1/293.1 kB 9.1 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/44.1 MB 16.9 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.5/44.1 MB 16.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.2/44.1 MB 15.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.9/44.1 MB 17.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 3.6/44.1 MB 16.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 4.3/44.1 MB 16.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 5.1/44.1 MB 16.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.8/44.1 MB 16.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 6.5/44.1 MB 16.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 7.2/44.1 MB 15.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 7.9/44.1 MB 15.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 8.7/44.1 MB 15.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 9.4/44.1 MB 15.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 10.1/44.1 MB 15.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 10.8/44.1 MB 15.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 11.6/44.1 MB 15.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 12.3/44.1 MB 15.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 13.0/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.7/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 14.4/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 15.1/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 15.9/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 16.6/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.4/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.1/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 18.8/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.5/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.3/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 21.0/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 21.7/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 22.4/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.1/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.8/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 24.5/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.2/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.0/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 26.7/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.4/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.1/44.1 MB 15.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 28.8/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 29.6/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.3/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.0/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.7/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.4/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.1/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.9/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 34.6/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.3/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.0/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.8/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.5/44.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.2/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 38.9/44.1 MB 15.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.6/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.4/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.1/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.8/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.5/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.3/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 12.8 MB/s eta 0:00:00\n",
      "Downloading piqp-0.2.4-cp311-cp311-win_amd64.whl (888 kB)\n",
      "   ---------------------------------------- 0.0/888.5 kB ? eta -:--:--\n",
      "   ---------------------------- ---------- 645.1/888.5 kB 20.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 888.5/888.5 kB 11.3 MB/s eta 0:00:00\n",
      "Downloading proxsuite-0.6.2-0-cp311-cp311-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.6/4.5 MB 20.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.0/4.5 MB 16.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.5/4.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.1/4.5 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.3/4.5 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.0/4.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.1/4.5 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.2/4.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.5/4.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.5/4.5 MB 9.6 MB/s eta 0:00:00\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading qpalm-1.2.2-cp311-cp311-win_amd64.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 151.5/151.5 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading quadprog-0.1.12-cp311-cp311-win_amd64.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/91.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 91.5/91.5 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading scs-3.2.4.post1-cp311-cp311-win_amd64.whl (8.4 MB)\n",
      "   ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.4 MB 16.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.0/8.4 MB 15.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.2/8.4 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.9/8.4 MB 15.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.6/8.4 MB 15.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.4/8.4 MB 15.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.1/8.4 MB 15.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.8/8.4 MB 15.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.5/8.4 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.3/8.4 MB 15.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.4 MB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.4/8.4 MB 15.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.4/8.4 MB 14.1 MB/s eta 0:00:00\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Using cached cmeel-0.53.3-py3-none-any.whl (20 kB)\n",
      "Downloading qdldl-0.1.7.post0-cp311-cp311-win_amd64.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.1/85.1 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: gputil, daqp, appdirs, werkzeug, tqdm, tensorboard-data-server, smmap, setproctitle, sentry-sdk, scipy, quadprog, PySocks, protobuf, piqp, markdown, lightning-utilities, highspy, grpcio, docker-pycreds, dill, cvxopt, cmeel, Click, absl-py, torch, tensorboard, scs, qpsolvers, qpalm, qdldl, pytorchcv, proxsuite, gitdb, ecos, clarabel, torchvision, torchmetrics, osqp, GitPython, gdown, wandb, avalanche-lib\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.12.0\n",
      "    Uninstalling scipy-1.12.0:\n",
      "      Successfully uninstalled scipy-1.12.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.42 PySocks-1.7.1 absl-py-2.1.0 appdirs-1.4.4 avalanche-lib-0.5.0 clarabel-0.7.1 cmeel-0.53.3 cvxopt-1.3.2 daqp-0.5.1 dill-0.3.8 docker-pycreds-0.4.0 ecos-2.0.13 gdown-5.1.0 gitdb-4.0.11 gputil-1.4.0 grpcio-1.62.1 highspy-1.7.1.dev1 lightning-utilities-0.10.1 markdown-3.5.2 osqp-0.6.5 piqp-0.2.4 protobuf-4.25.3 proxsuite-0.6.2 pytorchcv-0.0.67 qdldl-0.1.7.post0 qpalm-1.2.2 qpsolvers-4.3.1 quadprog-0.1.12 scipy-1.11.4 scs-3.2.4.post1 sentry-sdk-1.42.0 setproctitle-1.3.3 smmap-5.0.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 torch-2.2.1 torchmetrics-1.3.1 torchvision-0.17.1 tqdm-4.66.2 wandb-0.16.4 werkzeug-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install avalanche-lib==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7e729",
   "metadata": {},
   "source": [
    "tested with:\n",
    "- python 3.10\n",
    "- avalanche 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad2b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import avalanche\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9648a",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "first, we load the data.\n",
    "- The data is automatically downloaded the first time.\n",
    "- `n_experiences` defines the lenght of the stream. Today we train our model offline, so we set `n_experiences=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b171887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniforge\\envs\\791aa\\Lib\\site-packages\\avalanche\\benchmarks\\scenarios\\supervised.py:389: UserWarning: stream generator will be converted to a list.\n",
      "  warnings.warn(\"stream generator will be converted to a list.\")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import SplitCIFAR10\n",
    "from avalanche.benchmarks import benchmark_with_validation_stream\n",
    "\n",
    "# data is stored in $HOME/.avalanche - you can change this setting in $HOME/.avalanche/config.json\n",
    "benchmark = SplitCIFAR10(n_experiences=1)\n",
    "benchmark = benchmark_with_validation_stream(benchmark, validation_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b4f21",
   "metadata": {},
   "source": [
    "we take the data from the streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c41404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = benchmark.train_stream[0].dataset\n",
    "valid_data = benchmark.valid_stream[0].dataset\n",
    "test_data = benchmark.test_stream[0].dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11708f64",
   "metadata": {},
   "source": [
    "NOTE: colors are wrong due to augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fbe4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'label=0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_data[0][0].transpose(0,2).numpy())\n",
    "plt.title(f\"label={train_data[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b374b17",
   "metadata": {},
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e71f88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([100, 3, 32, 32])\n",
      "y: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "t: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "0, 100, 200, 300, "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_data, batch_size=100)\n",
    "for i, (x, y, t) in enumerate(dataloader):\n",
    "    # x is the input\n",
    "    # y is the target class\n",
    "    # t is the task label.\n",
    "    # We will use it for multi-task problems\n",
    "    pass\n",
    "    if i == 0:\n",
    "        print(f\"x.shape: {x.shape}\")\n",
    "        print(f\"y: {y}\")\n",
    "        print(f\"t: {t}\")\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=\", \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218664fc",
   "metadata": {},
   "source": [
    "# Model\n",
    "We use a resnet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60eeb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is the slimmed ResNet as used by Lopez et al. in the GEM paper.\"\"\"\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu, avg_pool2d\n",
    "from avalanche.models import DynamicModule\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(0, len(sizes) - 1):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
    "            if i < (len(sizes) - 2):\n",
    "                layers.append(nn.ReLU())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_planes,\n",
    "                    self.expansion * planes,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(self.expansion * planes),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes, nf):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = nf\n",
    "\n",
    "        self.conv1 = conv3x3(3, nf * 1)\n",
    "        self.bn1 = nn.BatchNorm2d(nf * 1)\n",
    "        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(nf * 8 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bsz = x.size(0)\n",
    "        out = relu(self.bn1(self.conv1(x.view(bsz, 3, 32, 32))))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def SlimResNet18(nclasses, nf=20):\n",
    "    \"\"\"Slimmed ResNet18.\"\"\"\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], nclasses, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f67c27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(20, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(20, 40, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(40, 80, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(80, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=160, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SlimResNet18(nclasses=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d5923",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b21d3fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4015: 100%|| 469/469 [01:32<00:00,  5.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cpu'  # do yourself a favor and use a gpu by setting device='cuda'\n",
    "model = SlimResNet18(nclasses=10)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.04)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Avalanche datasets have a training and eval mode (train/eval methods)\n",
    "# to activate different augmentations\n",
    "# don't forget to activate it!\n",
    "train_data = train_data.train()\n",
    "\n",
    "# Iterate over the dataset and train the model\n",
    "model.train()  # don't forget to set the training mode!\n",
    "for ep in range(10):  # 10 epoch is a bit on the low end. With a GPU you can run a larger experiment\n",
    "    dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=0)  # increase num_workers if you have more CPUs\n",
    "    pbar = tqdm(dataloader)\n",
    "    for (x, y, _) in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # the order matters!\n",
    "        # - reset the gradients\n",
    "        # - forward pass\n",
    "        # - backward pass\n",
    "        # - descent step\n",
    "        optimizer.zero_grad()   \n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f\"Loss: {loss.item():0.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017e21f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f079156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ACC: 0.8499: 100%|| 469/469 [00:32<00:00, 14.34it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "train_data = valid_data.eval()\n",
    "\n",
    "dataloader = DataLoader(valid_data, batch_size=32, num_workers=0)  # increase num_workers if you have more CPUs\n",
    "pbar = tqdm(dataloader)\n",
    "correct, tot = 0, 0\n",
    "for (x, y, _) in pbar:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    pred = model(x)\n",
    "    _, pred = torch.max(pred.data, 1)\n",
    "    correct += (pred == y).sum().item()\n",
    "    tot += x.shape[0]\n",
    "    pbar.set_description(f\"ACC: {correct / tot:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3281538b",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "Pick a couple of them to experiment with:\n",
    "\n",
    "- **resnet**: check the ResNet code. Do you understand everything? If not, check the documentation or ask for help.\n",
    "    - advanced version: now change the input transformations to change the input size of the images. Are you able to change the resnet architecture to make it compatible with the new image? Any change to the architecture is fine (just don't pad/crop the image...).\n",
    "- **dataloading**: If you have a large GPU (V100/A100), you need to feed the data fast enough, otherwise you are going to waste precious GPU cycles. Transformations can be expensive and dataloaders can make a big difference in performance.\n",
    "    - simple exercise: test and profile different augmentations from [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html). Play with the DataLoader parameters and measure its performance ([doc](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)). Try varying `num_workers`, `pin_memory`, and any other argument that you feel is relevant. Profile your code by timing the loading of the entire dataset in mini-batches, like you would do for a training epoch (without the forward/backward pass).\n",
    "    - advanced exercise: you can also try [FFCV](https://github.com/libffcv/ffcv). Its usage is a bit more involved since you need an additional dependency and you need to prepare the dataset, but you can make the data pipeline much faster with with it.\n",
    "- **augmentations matter**: try to train a model with and without augmentations.\n",
    "- **training stability and lr**: try to increase the learning rate (10x, 100x, ...). What happens to the learning curve? You can also try some learning rate scheduler.\n",
    "- **dropout**: as you know, dropout helps training DNN by regularizing the activations. But does it? You can try a small model such as a [SimpleMLP](https://avalanche-api.continualai.org/en/v0.3.1/generated/avalanche.models.SimpleMLP.html#avalanche.models.SimpleMLP). Does it always help? **hint**: as a general rule, if the model is too small (too shallow or not enough units), dropout will *decrease* the performance. This is a simple exercise to show you that scale matters when you make hyperparameter choices.\n",
    "- **add early stopping + model checkpointing**\n",
    "- **reproduce sota for CIFAR100**: use this notebook to reproduce a result from [this repo](https://github.com/weiaicunzai/pytorch-cifar100). NOTE: our resnet18 is slightly different from theirs (slim version, less units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6451ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
