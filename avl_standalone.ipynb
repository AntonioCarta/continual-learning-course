{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avalanche Standalone\n",
    "\n",
    "this notebook shows you how to use Avalanche components inside your own training loops. We will see how to use:\n",
    "- Benchmarks\n",
    "- Dynamic and MultiTask Models\n",
    "- Replay methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ü§ù Run it on Google Colab\n",
    "\n",
    "You can run _this chapter_ and play with it on Google Colaboratory: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AntonioCarta/avalanche-demo/blob/main/avl_standalone.ipynb)\n",
    "\n",
    "https://github.com/AntonioCarta/avalanche-demo/blob/main/avl_standalone.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install Avalanche\n",
    "\n",
    "First, let's install Avalanche. You can skip this step if you have installed it already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install avalanche-lib==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can import benchmarks from the `avl.benchmarks` module. We are going to use `SplitMNIST`, the class-incremental MNIST stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks import SplitMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 5, len test: 5\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=False\n",
    ")\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "print(f\"len train: {len(train_stream)}, len test: {len(test_stream)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) - T0, classes=[2, 3]\n",
      "(1) - T0, classes=[8, 6]\n",
      "(2) - T0, classes=[5, 7]\n",
      "(3) - T0, classes=[0, 9]\n",
      "(4) - T0, classes=[1, 4]\n"
     ]
    }
   ],
   "source": [
    "for exp in train_stream:\n",
    "    eid = exp.current_experience\n",
    "    curr_classes = exp.classes_in_this_experience\n",
    "    tid = exp.task_label\n",
    "    print(f\"({eid}) - T{tid}, classes={curr_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Avalanche does not order classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can create a task-aware benchmark by setting `return_task_id=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 5, len test: 5\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True\n",
    ")\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "print(f\"len train: {len(train_stream)}, len test: {len(test_stream)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) - T0, classes=[0, 5]\n",
      "(1) - T1, classes=[8, 7]\n",
      "(2) - T2, classes=[9, 3]\n",
      "(3) - T3, classes=[2, 4]\n",
      "(4) - T4, classes=[1, 6]\n"
     ]
    }
   ],
   "source": [
    "for exp in train_stream:\n",
    "    eid = exp.current_experience\n",
    "    curr_classes = exp.classes_in_this_experience\n",
    "    tid = exp.task_label\n",
    "    print(f\"({eid}) - T{tid}, classes={curr_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x, **kwargs):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "model = MLP()\n",
    "model(torch.randn(32, 784))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP is ignoring task_labels. You can use Avalanche MultiHeadClassifier to split the output layer by task id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1224, -0.0981,  0.0701,  0.1571, -0.0390,  0.0817, -0.0917,  0.0924,\n",
       "          0.0396, -0.0584],\n",
       "        [-0.0256, -0.2319,  0.0117,  0.2477,  0.0060,  0.1637, -0.0587, -0.0685,\n",
       "          0.0925, -0.0490],\n",
       "        [ 0.1753, -0.0766,  0.0769,  0.1029,  0.0381,  0.0859, -0.0243,  0.0646,\n",
       "          0.0877, -0.0614],\n",
       "        [ 0.1560, -0.1191,  0.0392,  0.1476, -0.0180,  0.0283, -0.1122, -0.0116,\n",
       "          0.1618,  0.0541],\n",
       "        [ 0.1224,  0.0200,  0.0185,  0.1189,  0.0350,  0.0684, -0.2346,  0.0555,\n",
       "         -0.0674, -0.1834],\n",
       "        [ 0.0324, -0.0390,  0.0744,  0.1455, -0.0191, -0.0209, -0.1493, -0.1253,\n",
       "          0.0086, -0.1311],\n",
       "        [ 0.0764, -0.0901, -0.0229,  0.1111, -0.0336, -0.0343, -0.1621, -0.0245,\n",
       "          0.0695, -0.0850],\n",
       "        [-0.0245, -0.0969,  0.0976,  0.1234,  0.0315,  0.0225, -0.0494,  0.0012,\n",
       "          0.1043, -0.0882],\n",
       "        [-0.0150, -0.0201, -0.0356,  0.0671,  0.0365,  0.0346, -0.1827,  0.1166,\n",
       "          0.0902, -0.0169],\n",
       "        [ 0.1559, -0.0920,  0.2084,  0.1894, -0.0662,  0.0494, -0.1349, -0.0111,\n",
       "          0.0319, -0.0840],\n",
       "        [ 0.0219, -0.1386, -0.0207,  0.1378,  0.0446,  0.0253, -0.0383,  0.0651,\n",
       "          0.0532, -0.0643],\n",
       "        [ 0.0209, -0.0283,  0.1552,  0.1950,  0.0534,  0.0817, -0.1339, -0.1281,\n",
       "          0.0062, -0.0738],\n",
       "        [ 0.0452, -0.1301,  0.1185,  0.1898,  0.1112,  0.0146, -0.1272,  0.0192,\n",
       "          0.1308, -0.0953],\n",
       "        [ 0.1163, -0.1373,  0.0154,  0.1408,  0.0675,  0.0760, -0.1175,  0.0345,\n",
       "         -0.0020, -0.0530],\n",
       "        [-0.0555, -0.0033,  0.0983,  0.1081,  0.0080, -0.0273, -0.2483, -0.0119,\n",
       "          0.0950, -0.0797],\n",
       "        [ 0.0087, -0.0325, -0.0929,  0.1330,  0.0049, -0.1059, -0.1313,  0.0363,\n",
       "          0.0520, -0.0994],\n",
       "        [ 0.0665,  0.0019,  0.1005, -0.0287,  0.0993,  0.0280, -0.0611, -0.0798,\n",
       "         -0.0088, -0.1231],\n",
       "        [ 0.0632, -0.2173,  0.1130,  0.1699,  0.0604, -0.0520, -0.0743, -0.0581,\n",
       "          0.0952, -0.1704],\n",
       "        [ 0.0921, -0.0704,  0.0790,  0.1511,  0.0399, -0.0048, -0.0664, -0.0103,\n",
       "         -0.0505,  0.0672],\n",
       "        [ 0.0430, -0.1244,  0.1444,  0.1724, -0.0087, -0.0142, -0.0274, -0.0850,\n",
       "         -0.0193, -0.0336],\n",
       "        [ 0.1854,  0.0043,  0.1347,  0.1939,  0.0190,  0.0891, -0.0754, -0.0398,\n",
       "         -0.0288, -0.0380],\n",
       "        [ 0.0444, -0.1111,  0.0050,  0.1241, -0.0496,  0.1087, -0.1274, -0.0154,\n",
       "          0.0801,  0.0145],\n",
       "        [ 0.0462, -0.0388,  0.1083,  0.1290, -0.0045,  0.0070, -0.1731, -0.0955,\n",
       "          0.0291, -0.1736],\n",
       "        [-0.0039, -0.1316, -0.0121,  0.0297, -0.1277,  0.1052, -0.1361, -0.0420,\n",
       "          0.0424, -0.1043],\n",
       "        [ 0.0610, -0.0869,  0.0651,  0.1518,  0.1366,  0.0259,  0.0747,  0.0363,\n",
       "         -0.0173,  0.0429],\n",
       "        [ 0.0672, -0.1036,  0.1034,  0.0859, -0.0647, -0.0211, -0.1778, -0.1035,\n",
       "          0.0764, -0.1001],\n",
       "        [-0.0620, -0.1236,  0.0880,  0.0676, -0.0055,  0.0823, -0.2278,  0.0784,\n",
       "         -0.0119, -0.0184],\n",
       "        [ 0.1488, -0.1167, -0.0103,  0.1314, -0.0956, -0.1476, -0.1535,  0.0034,\n",
       "          0.1324, -0.1216],\n",
       "        [-0.0078, -0.0667,  0.0656,  0.1711, -0.0530,  0.1691, -0.1089, -0.0042,\n",
       "         -0.0467, -0.0712],\n",
       "        [ 0.0903, -0.1049,  0.0194,  0.0368,  0.0267, -0.0424, -0.0406,  0.0368,\n",
       "         -0.0070,  0.0806],\n",
       "        [ 0.0267, -0.0486,  0.1166,  0.1564,  0.1011, -0.0447, -0.2174, -0.0918,\n",
       "          0.1363, -0.0141],\n",
       "        [ 0.0022, -0.1454,  0.0604,  0.0624,  0.0232, -0.0099, -0.1102, -0.0692,\n",
       "          0.0198, -0.0643]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 784)\n",
    "t = torch.randint(low=0, high=4, size=(32,))\n",
    "model(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskDecorator(\n",
      "  (model): MLP(\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): MultiHeadClassifier(\n",
      "    (classifiers): ModuleDict(\n",
      "      (0): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models import as_multitask\n",
    "\n",
    "model_mt = as_multitask(MLP(), 'classifier')\n",
    "print(model_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 0, 1, 2, 1, 2, 2, 0, 0, 2, 2, 2, 2, 3, 2, 2, 0, 0, 1, 0, 1, 0,\n",
       "        1, 2, 1, 2, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still doesn't know about all the tasks because it has neven seen them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\avalanche\\models\\dynamic_modules.py:163\u001b[0m, in \u001b[0;36mMultiTaskModule.forward\u001b[1;34m(self, x, task_labels)\u001b[0m\n\u001b[0;32m    161\u001b[0m task_mask \u001b[38;5;241m=\u001b[39m task_labels \u001b[38;5;241m==\u001b[39m task\n\u001b[0;32m    162\u001b[0m x_task \u001b[38;5;241m=\u001b[39m x[task_mask]\n\u001b[1;32m--> 163\u001b[0m out_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_task\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, (\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti-head assumes mini-batches of 2 dimensions \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<batch, classes>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    167\u001b[0m n_labels_head \u001b[38;5;241m=\u001b[39m out_task\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\avalanche\\models\\helper_method.py:69\u001b[0m, in \u001b[0;36mMultiTaskDecorator.forward_single_task\u001b[1;34m(self, x, task_label)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_single_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, task_label: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m     68\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_label\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\avalanche\\models\\dynamic_modules.py:155\u001b[0m, in \u001b[0;36mMultiTaskModule.forward\u001b[1;34m(self, x, task_labels)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_all_tasks(x)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_labels, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# fast path. mini-batch is single task.\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     unique_tasks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(task_labels)\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\avalanche\\models\\dynamic_modules.py:417\u001b[0m, in \u001b[0;36mMultiHeadClassifier.forward_single_task\u001b[1;34m(self, x, task_label)\u001b[0m\n\u001b[0;32m    415\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adaptation_device\n\u001b[0;32m    416\u001b[0m task_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(task_label)\n\u001b[1;32m--> 417\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_label\u001b[49m\u001b[43m]\u001b[49m(x)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking:\n\u001b[0;32m    419\u001b[0m     au_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_units_T\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mD:\\miniforge\\envs\\791aa\\Lib\\site-packages\\torch\\nn\\modules\\container.py:461\u001b[0m, in \u001b[0;36mModuleDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;129m@_copy_to_script_wrapper\u001b[39m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Module:\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "model_mt(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to adapt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskDecorator(\n",
      "  (model): MLP(\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): MultiHeadClassifier(\n",
      "    (classifiers): ModuleDict(\n",
      "      (0): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (1): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (2): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (3): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (4): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "\n",
    "for exp in benchmark.train_stream:\n",
    "    avalanche_model_adaptation(model_mt, exp)\n",
    "\n",
    "print(model_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model has been adapted to all the tasks. A separate head for each task is available for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+03, -1.0000e+03,  4.3231e-02, -1.0000e+03, -3.0058e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 9.6094e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -2.3990e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 7.2177e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -9.8190e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 2.4720e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -9.9390e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0763e-01,  2.4434e-01, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  4.2126e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.4921e-02],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03,  5.3216e-04,  5.6687e-02, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  1.1381e-01, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.5525e-01],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  1.1807e-01, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.5461e-01],\n",
       "        [-7.0109e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.4385e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 8.7607e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -7.8859e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  1.1826e-01, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.3240e-01],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.1904e-03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.0978e-01],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  8.8192e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  8.3231e-02],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  1.6113e-01, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  2.9580e-02],\n",
       "        [-1.0000e+03, -1.0000e+03,  1.1413e-01, -1.0000e+03,  4.6000e-03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  6.1846e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -5.4337e-03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  1.6103e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  8.8709e-02],\n",
       "        [ 3.4886e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.5129e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 1.4386e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -4.1475e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -6.7548e-02,  1.0026e-01, -1.0000e+03],\n",
       "        [-1.1926e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -8.1537e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03,  5.0485e-02,  1.2023e-01, -1.0000e+03],\n",
       "        [ 3.1759e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -7.1352e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03,  1.0447e-01,  5.1903e-02, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -9.2246e-03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  7.3985e-02],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -3.4452e-02,  1.4127e-01, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  1.4407e-01, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  3.1664e-02],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  2.0519e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.3986e-02],\n",
       "        [-7.5920e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -9.9868e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03,  2.9722e-02,  1.0721e-02, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -4.5247e-02, -2.8611e-02, -1.0000e+03]],\n",
       "       grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mt(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training loop - Finetuning (with Multi-head model)\n",
    "\n",
    "We can train the model continually by iterating over the `train_stream` provided by the scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training import Naive\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# scenario\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# model\n",
    "model = as_multitask(MLP(), 'classifier')\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0)\n",
      "Train Epoch: 0 \tLoss: 0.040961\n",
      "Train Epoch: 1 \tLoss: 0.023422\n",
      "Experience (1)\n",
      "Train Epoch: 0 \tLoss: 0.028009\n",
      "Train Epoch: 1 \tLoss: 0.038673\n",
      "Experience (2)\n",
      "Train Epoch: 0 \tLoss: 0.063915\n",
      "Train Epoch: 1 \tLoss: 0.040975\n",
      "Experience (3)\n",
      "Train Epoch: 0 \tLoss: 0.059366\n",
      "Train Epoch: 1 \tLoss: 0.019216\n",
      "Experience (4)\n",
      "Train Epoch: 0 \tLoss: 0.066897\n",
      "Train Epoch: 1 \tLoss: 0.011423\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "from avalanche.models.dynamic_optimizers import reset_optimizer\n",
    "\n",
    "device = 'cpu'\n",
    "num_epochs = 2\n",
    "\n",
    "for exp in benchmark.train_stream:\n",
    "    print(f\"Experience ({exp.current_experience})\")\n",
    "    model.train()\n",
    "\n",
    "    # AVALANCHE: model adaptation step adds new parameters\n",
    "    # In our model: adds a new head for each task\n",
    "    avalanche_model_adaptation(model, exp)\n",
    "    # AVALANCHE: We just added parameters to the model. We must also update the optimizer\n",
    "    reset_optimizer(optimizer, model)\n",
    "    \n",
    "    dataset = exp.dataset\n",
    "    dataset = dataset.train()  # AVALANCHE: activate correct transformation group\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        dl = DataLoader(dataset, batch_size=128)\n",
    "        for x, y, t in dl:\n",
    "          x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          # AVALANCHE: MultiTaskModels need task labels\n",
    "          output = model(x, t)\n",
    "          loss = F.cross_entropy(output, y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Replay Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# scenario\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# model\n",
    "model = as_multitask(MLP(), 'classifier')\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 30, current size: 0\n",
      "Max buffer size: 30, current size: 0\n",
      "Experience (0)\n",
      "Train Epoch: 0 \tLoss: 0.040961\n",
      "Train Epoch: 1 \tLoss: 0.023422\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "\n",
      "Experience (1)\n",
      "Train Epoch: 0 \tLoss: 0.028027\n",
      "Train Epoch: 1 \tLoss: 0.038651\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "Experience (2)\n",
      "Train Epoch: 0 \tLoss: 0.063074\n",
      "Train Epoch: 1 \tLoss: 0.041174\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8]\n",
      "\n",
      "Experience (3)\n",
      "Train Epoch: 0 \tLoss: 0.059068\n",
      "Train Epoch: 1 \tLoss: 0.019269\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 6, 6, 6, 6, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 8, 8, 8, 9, 9, 9, 3, 3, 3, 3]\n",
      "\n",
      "Experience (4)\n",
      "Train Epoch: 0 \tLoss: 0.066729\n",
      "Train Epoch: 1 \tLoss: 0.011459\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 6, 6, 6, 1, 1, 1, 2, 2, 2, 0, 0, 0, 8, 8, 8, 9, 9, 9, 3, 3, 3, 4, 4, 4, 7, 7, 7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "\n",
    "device = 'cpu'\n",
    "num_epochs = 2\n",
    "\n",
    "# AVALANCHE: init replay buffer\n",
    "storage_p = ParametricBuffer(\n",
    "    max_size=30,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    ")\n",
    "\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")   \n",
    "for exp in benchmark.train_stream:\n",
    "    print(f\"Experience ({exp.current_experience})\")\n",
    "    model.train()\n",
    "    avalanche_model_adaptation(model, exp)\n",
    "    reset_optimizer(optimizer, model)\n",
    "    dataset = exp.dataset\n",
    "    dataset = dataset.train()\n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        # AVALANCHE: ReplayDataLoader to sample jointly from buffer and current data.\n",
    "        dl = ReplayDataLoader(dataset, storage_p.buffer, batch_size=128)\n",
    "        for x, y, t in dl:\n",
    "          x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          output = model(x, t)\n",
    "          loss = F.cross_entropy(output, y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # AVALANCHE: you can use a SimpleNamespace if you want to use Avalanche components with your own code.\n",
    "    strategy_state = SimpleNamespace(experience=exp)\n",
    "    # AVALANCHE: update replay buffer\n",
    "    storage_p.update(strategy_state)\n",
    "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "    print(f\"class targets: {list(storage_p.buffer.targets)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
