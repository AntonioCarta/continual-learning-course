{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avalanche Standalone\n",
    "\n",
    "this notebook shows you how to use Avalanche components inside your own training loops. We will see how to use:\n",
    "- Benchmarks\n",
    "- Dynamic and MultiTask Models\n",
    "- Replay methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ü§ù Run it on Google Colab\n",
    "\n",
    "You can run _this chapter_ and play with it on Google Colaboratory: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AntonioCarta/avalanche-demo/blob/main/avl_standalone.ipynb)\n",
    "\n",
    "https://github.com/AntonioCarta/avalanche-demo/blob/main/avl_standalone.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install Avalanche\n",
    "\n",
    "First, let's install Avalanche. You can skip this step if you have installed it already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install avalanche-lib==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can import benchmarks from the `avl.benchmarks` module. We are going to use `SplitMNIST`, the class-incremental MNIST stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks import SplitMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 5, len test: 5\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=False\n",
    ")\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "print(f\"len train: {len(train_stream)}, len test: {len(test_stream)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) - T0, classes=[9, 3]\n",
      "(1) - T0, classes=[2, 5]\n",
      "(2) - T0, classes=[0, 7]\n",
      "(3) - T0, classes=[4, 6]\n",
      "(4) - T0, classes=[8, 1]\n"
     ]
    }
   ],
   "source": [
    "for exp in train_stream:\n",
    "    eid = exp.current_experience\n",
    "    curr_classes = exp.classes_in_this_experience\n",
    "    tid = exp.task_label\n",
    "    print(f\"({eid}) - T{tid}, classes={curr_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Avalanche does not order classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can create a task-aware benchmark by setting `return_task_id=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 5, len test: 5\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True\n",
    ")\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "print(f\"len train: {len(train_stream)}, len test: {len(test_stream)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) - T0, classes=[3, 5]\n",
      "(1) - T1, classes=[0, 6]\n",
      "(2) - T2, classes=[2, 7]\n",
      "(3) - T3, classes=[8, 4]\n",
      "(4) - T4, classes=[1, 9]\n"
     ]
    }
   ],
   "source": [
    "for exp in train_stream:\n",
    "    eid = exp.current_experience\n",
    "    curr_classes = exp.classes_in_this_experience\n",
    "    tid = exp.task_label\n",
    "    print(f\"({eid}) - T{tid}, classes={curr_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x, **kwargs):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "model = MLP()\n",
    "model(torch.randn(32, 784))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP is ignoring task_labels. You can use Avalanche MultiHeadClassifier to split the output layer by task id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0281, -0.0436, -0.0610,  0.0595, -0.0422,  0.0715, -0.0210, -0.1347,\n",
       "          0.1593,  0.1408],\n",
       "        [-0.0713, -0.1221, -0.0039, -0.1138,  0.0577,  0.1070,  0.0991, -0.0745,\n",
       "          0.0892,  0.1129],\n",
       "        [-0.0980, -0.1482, -0.0773, -0.0455, -0.0408,  0.0084, -0.0562,  0.0264,\n",
       "          0.0495,  0.0881],\n",
       "        [-0.1388, -0.1217,  0.1134,  0.0038, -0.0263,  0.0118, -0.0708, -0.1494,\n",
       "          0.0318,  0.1721],\n",
       "        [-0.1134, -0.0184, -0.0700,  0.0270,  0.0119,  0.0987, -0.1898, -0.0032,\n",
       "          0.0830,  0.1565],\n",
       "        [-0.1071, -0.0931, -0.0257,  0.1175,  0.0004,  0.1834, -0.0406, -0.0176,\n",
       "          0.1134,  0.1953],\n",
       "        [-0.1933,  0.0057, -0.0682, -0.0544,  0.0223,  0.0401, -0.0104, -0.1890,\n",
       "          0.0552,  0.1008],\n",
       "        [-0.0128, -0.0296, -0.1234,  0.0269, -0.0506,  0.0852, -0.0787, -0.0647,\n",
       "          0.0424,  0.0081],\n",
       "        [-0.1174, -0.0601,  0.0206,  0.1607,  0.1086,  0.0784, -0.1163, -0.0462,\n",
       "          0.0632,  0.0500],\n",
       "        [-0.0510, -0.0619,  0.0220, -0.0398,  0.0344,  0.2008, -0.1179, -0.1553,\n",
       "          0.0070,  0.1037],\n",
       "        [-0.0147,  0.0346, -0.0144, -0.0398,  0.0527,  0.1141, -0.0533,  0.0854,\n",
       "          0.0585,  0.0969],\n",
       "        [-0.0179, -0.1724, -0.0440,  0.0260, -0.0206,  0.0732, -0.0749,  0.0182,\n",
       "          0.2043, -0.0407],\n",
       "        [ 0.0230,  0.0372, -0.1336, -0.0152, -0.1225,  0.1282,  0.0525,  0.0291,\n",
       "         -0.0281,  0.0854],\n",
       "        [-0.0476, -0.2445, -0.0785,  0.1100,  0.0146,  0.1054, -0.1248, -0.0209,\n",
       "          0.0838, -0.0787],\n",
       "        [-0.0161, -0.1174,  0.0123, -0.0731,  0.0099,  0.1119, -0.0408, -0.0398,\n",
       "          0.0263, -0.0140],\n",
       "        [-0.0421, -0.0403, -0.0230,  0.0202, -0.0470,  0.0135, -0.0528,  0.0396,\n",
       "          0.0475, -0.0710],\n",
       "        [ 0.0239, -0.1337,  0.0675,  0.0613,  0.0669,  0.1330,  0.0782, -0.1622,\n",
       "          0.0706,  0.0290],\n",
       "        [-0.0583, -0.1775, -0.0803, -0.0306,  0.1226,  0.1156, -0.1625, -0.1055,\n",
       "          0.0778,  0.1347],\n",
       "        [-0.1231, -0.1566, -0.0391,  0.0349,  0.0781,  0.0984,  0.0399,  0.0601,\n",
       "         -0.0572, -0.0440],\n",
       "        [ 0.0096, -0.1265,  0.0659,  0.0411, -0.0065, -0.0030,  0.1540, -0.0492,\n",
       "          0.0108,  0.0637],\n",
       "        [-0.1035, -0.0946, -0.0185, -0.0258, -0.0377,  0.1177,  0.0142, -0.2353,\n",
       "          0.0094,  0.0848],\n",
       "        [-0.0117, -0.1475, -0.0180, -0.0170,  0.0114,  0.0256, -0.1174, -0.1299,\n",
       "         -0.0316,  0.0476],\n",
       "        [-0.0184, -0.1852, -0.0491, -0.0288, -0.0540,  0.0661, -0.2075,  0.0087,\n",
       "          0.0986,  0.0810],\n",
       "        [-0.0036, -0.0508,  0.0555,  0.0352, -0.0369,  0.1779, -0.0307, -0.1240,\n",
       "          0.0718,  0.1906],\n",
       "        [-0.0726, -0.0904,  0.0278,  0.1108,  0.0649,  0.1543, -0.0711, -0.1158,\n",
       "          0.0330,  0.0118],\n",
       "        [-0.0921, -0.3455, -0.0561, -0.0275, -0.0737,  0.0472, -0.0780, -0.0651,\n",
       "          0.0673,  0.1308],\n",
       "        [ 0.0063, -0.1051, -0.0144, -0.0732, -0.0543,  0.0009, -0.1050, -0.0883,\n",
       "         -0.0084,  0.0693],\n",
       "        [-0.0089, -0.1343, -0.0149, -0.0162, -0.0545,  0.1104, -0.1433, -0.0317,\n",
       "         -0.0476,  0.0206],\n",
       "        [-0.0524, -0.1100, -0.0490,  0.0744, -0.0305,  0.1250, -0.1230, -0.1298,\n",
       "         -0.0447,  0.1241],\n",
       "        [ 0.0343, -0.1641, -0.0690,  0.0683,  0.0812,  0.0924, -0.0312,  0.0578,\n",
       "          0.0722,  0.1383],\n",
       "        [-0.1077, -0.1244, -0.0863,  0.0137,  0.0411,  0.1787, -0.0204,  0.0173,\n",
       "          0.0140,  0.1758],\n",
       "        [-0.0287, -0.2015, -0.1539, -0.0300, -0.0874,  0.0421, -0.1450, -0.0916,\n",
       "          0.0070,  0.0305]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 784)\n",
    "t = torch.randint(low=0, high=4, size=(32,))\n",
    "model(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskDecorator(\n",
      "  (model): MLP(\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): MultiHeadClassifier(\n",
      "    (classifiers): ModuleDict(\n",
      "      (0): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models import as_multitask\n",
    "\n",
    "model_mt = as_multitask(MLP(), 'classifier')\n",
    "print(model_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 0, 1, 0, 1, 1, 0, 2, 1, 2, 0, 3, 3, 1, 3, 3, 3, 2, 3, 1, 0, 2, 2,\n",
       "        0, 1, 3, 3, 1, 1, 1, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still doesn't know about all the tasks because it has neven seen them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:163\u001b[0m, in \u001b[0;36mMultiTaskModule.forward\u001b[1;34m(self, x, task_labels)\u001b[0m\n\u001b[0;32m    161\u001b[0m task_mask \u001b[38;5;241m=\u001b[39m task_labels \u001b[38;5;241m==\u001b[39m task\n\u001b[0;32m    162\u001b[0m x_task \u001b[38;5;241m=\u001b[39m x[task_mask]\n\u001b[1;32m--> 163\u001b[0m out_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_task\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, (\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti-head assumes mini-batches of 2 dimensions \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<batch, classes>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    167\u001b[0m n_labels_head \u001b[38;5;241m=\u001b[39m out_task\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\avalanche\\models\\helper_method.py:69\u001b[0m, in \u001b[0;36mMultiTaskDecorator.forward_single_task\u001b[1;34m(self, x, task_label)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_single_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, task_label: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m     68\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_label\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:155\u001b[0m, in \u001b[0;36mMultiTaskModule.forward\u001b[1;34m(self, x, task_labels)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_all_tasks(x)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_labels, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# fast path. mini-batch is single task.\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     unique_tasks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(task_labels)\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:417\u001b[0m, in \u001b[0;36mMultiHeadClassifier.forward_single_task\u001b[1;34m(self, x, task_label)\u001b[0m\n\u001b[0;32m    415\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adaptation_device\n\u001b[0;32m    416\u001b[0m task_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(task_label)\n\u001b[1;32m--> 417\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_label\u001b[49m\u001b[43m]\u001b[49m(x)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking:\n\u001b[0;32m    419\u001b[0m     au_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_units_T\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\mambaforge\\envs\\791aa\\lib\\site-packages\\torch\\nn\\modules\\container.py:461\u001b[0m, in \u001b[0;36mModuleDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;129m@_copy_to_script_wrapper\u001b[39m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Module:\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "model_mt(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to adapt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskDecorator(\n",
      "  (model): MLP(\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): MultiHeadClassifier(\n",
      "    (classifiers): ModuleDict(\n",
      "      (0): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (1): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (2): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (3): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (4): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "\n",
    "for exp in benchmark.train_stream:\n",
    "    avalanche_model_adaptation(model_mt, exp)\n",
    "\n",
    "print(model_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model has been adapted to all the tasks. A separate head for each task is available for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  2.9020e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -5.3654e-02, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  2.3616e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0296e-02, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  7.9147e-02, -1.0000e+03,\n",
       "          5.7862e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 3.6879e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  8.3463e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  1.5846e-01, -1.0000e+03,\n",
       "          1.1499e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-8.2920e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.5061e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 7.6269e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  1.0547e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  9.7365e-02, -1.0000e+03,\n",
       "          3.5479e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -8.9809e-03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0321e-02, -1.0000e+03, -1.0000e+03],\n",
       "        [ 6.2552e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  1.8096e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -3.2448e-03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.2561e-02, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  3.4404e-03, -1.0000e+03,\n",
       "          8.0731e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -5.2457e-03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -2.3071e-02, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  2.3750e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0801e-02, -1.0000e+03],\n",
       "        [-1.3516e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -4.1860e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -3.6264e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -9.1599e-03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  4.8499e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -5.8637e-03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.2755e-01,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.5641e-02, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03,  6.9405e-02, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -3.1267e-02, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  2.3543e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03,  2.8508e-02, -1.0000e+03],\n",
       "        [ 1.9603e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  9.9867e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  2.4159e-01, -1.0000e+03,\n",
       "          8.4460e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03,  1.9442e-02, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03,  2.3662e-02, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03,  6.2257e-02, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -5.7289e-02, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03,  2.2666e-01, -1.0000e+03,\n",
       "         -6.6677e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-2.8983e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  1.2265e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  2.6361e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03,  3.8156e-03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.8473e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03,  7.8570e-02, -1.0000e+03],\n",
       "        [ 3.2880e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  7.1013e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 1.0275e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  9.9732e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 1.1063e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  4.7749e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -9.4846e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.0811e-01, -1.0000e+03]],\n",
       "       grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mt(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training loop - Finetuning (with Multi-head model)\n",
    "\n",
    "We can train the model continually by iterating over the `train_stream` provided by the scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training import Naive\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# scenario\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# model\n",
    "model = as_multitask(MLP(), 'classifier')\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0)\n",
      "Train Epoch: 0 \tLoss: 0.040961\n",
      "Train Epoch: 1 \tLoss: 0.023422\n",
      "Experience (1)\n",
      "Train Epoch: 0 \tLoss: 0.028009\n",
      "Train Epoch: 1 \tLoss: 0.038673\n",
      "Experience (2)\n",
      "Train Epoch: 0 \tLoss: 0.063915\n",
      "Train Epoch: 1 \tLoss: 0.040975\n",
      "Experience (3)\n",
      "Train Epoch: 0 \tLoss: 0.059366\n",
      "Train Epoch: 1 \tLoss: 0.019216\n",
      "Experience (4)\n",
      "Train Epoch: 0 \tLoss: 0.066897\n",
      "Train Epoch: 1 \tLoss: 0.011423\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "from avalanche.models.dynamic_optimizers import reset_optimizer\n",
    "\n",
    "device = 'cpu'\n",
    "num_epochs = 2\n",
    "\n",
    "for exp in benchmark.train_stream:\n",
    "    print(f\"Experience ({exp.current_experience})\")\n",
    "    model.train()\n",
    "\n",
    "    # AVALANCHE: model adaptation step adds new parameters\n",
    "    # In our model: adds a new head for each task\n",
    "    avalanche_model_adaptation(model, exp)\n",
    "    # AVALANCHE: We just added parameters to the model. We must also update the optimizer\n",
    "    reset_optimizer(optimizer, model)\n",
    "    \n",
    "    dataset = exp.dataset\n",
    "    dataset = dataset.train()  # AVALANCHE: activate correct transformation group\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        dl = DataLoader(dataset, batch_size=128)\n",
    "        for x, y, t in dl:\n",
    "          x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          # AVALANCHE: MultiTaskModels need task labels\n",
    "          output = model(x, t)\n",
    "          loss = F.cross_entropy(output, y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Replay Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# scenario\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# model\n",
    "model = as_multitask(MLP(), 'classifier')\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 30, current size: 0\n",
      "Max buffer size: 30, current size: 0\n",
      "Experience (0)\n",
      "Train Epoch: 0 \tLoss: 0.040961\n",
      "Train Epoch: 1 \tLoss: 0.023422\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "\n",
      "Experience (1)\n",
      "Train Epoch: 0 \tLoss: 0.028027\n",
      "Train Epoch: 1 \tLoss: 0.038651\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "Experience (2)\n",
      "Train Epoch: 0 \tLoss: 0.063074\n",
      "Train Epoch: 1 \tLoss: 0.041174\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8]\n",
      "\n",
      "Experience (3)\n",
      "Train Epoch: 0 \tLoss: 0.059068\n",
      "Train Epoch: 1 \tLoss: 0.019269\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 6, 6, 6, 6, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 8, 8, 8, 9, 9, 9, 3, 3, 3, 3]\n",
      "\n",
      "Experience (4)\n",
      "Train Epoch: 0 \tLoss: 0.066729\n",
      "Train Epoch: 1 \tLoss: 0.011459\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 6, 6, 6, 1, 1, 1, 2, 2, 2, 0, 0, 0, 8, 8, 8, 9, 9, 9, 3, 3, 3, 4, 4, 4, 7, 7, 7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "\n",
    "device = 'cpu'\n",
    "num_epochs = 2\n",
    "\n",
    "# AVALANCHE: init replay buffer\n",
    "storage_p = ParametricBuffer(\n",
    "    max_size=30,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    ")\n",
    "\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")   \n",
    "for exp in benchmark.train_stream:\n",
    "    print(f\"Experience ({exp.current_experience})\")\n",
    "    model.train()\n",
    "    avalanche_model_adaptation(model, exp)\n",
    "    reset_optimizer(optimizer, model)\n",
    "    dataset = exp.dataset\n",
    "    dataset = dataset.train()\n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        # AVALANCHE: ReplayDataLoader to sample jointly from buffer and current data.\n",
    "        dl = ReplayDataLoader(dataset, storage_p.buffer, batch_size=128)\n",
    "        for x, y, t in dl:\n",
    "          x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          output = model(x, t)\n",
    "          loss = F.cross_entropy(output, y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # AVALANCHE: you can use a SimpleNamespace if you want to use Avalanche components with your own code.\n",
    "    strategy_state = SimpleNamespace(experience=exp)\n",
    "    # AVALANCHE: update replay buffer\n",
    "    storage_p.update(strategy_state)\n",
    "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "    print(f\"class targets: {list(storage_p.buffer.targets)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
