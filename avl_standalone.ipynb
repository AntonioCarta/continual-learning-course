{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avalanche Standalone\n",
    "\n",
    "this notebook shows you how to use Avalanche components inside your own training loops. We will see how to use:\n",
    "- Benchmarks\n",
    "- Dynamic and MultiTask Models\n",
    "- Replay methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ü§ù Run it on Google Colab\n",
    "\n",
    "You can run _this chapter_ and play with it on Google Colaboratory: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AntonioCarta/avalanche-demo/blob/main/avl_standalone.ipynb)\n",
    "\n",
    "https://github.com/AntonioCarta/avalanche-demo/blob/main/avl_standalone.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install Avalanche\n",
    "\n",
    "First, let's install Avalanche. You can skip this step if you have installed it already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install avalanche-lib==0.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can import benchmarks from the `avl.benchmarks` module. We are going to use `SplitMNIST`, the class-incremental MNIST stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks import SplitMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 5, len test: 5\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=False\n",
    ")\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "print(f\"len train: {len(train_stream)}, len test: {len(test_stream)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) - T0, classes=[3, 5]\n",
      "(1) - T0, classes=[8, 7]\n",
      "(2) - T0, classes=[1, 2]\n",
      "(3) - T0, classes=[0, 4]\n",
      "(4) - T0, classes=[9, 6]\n"
     ]
    }
   ],
   "source": [
    "for exp in train_stream:\n",
    "    eid = exp.current_experience\n",
    "    curr_classes = exp.classes_in_this_experience\n",
    "    tid = exp.task_label\n",
    "    print(f\"({eid}) - T{tid}, classes={curr_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Avalanche does not order classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can create a task-aware benchmark by setting `return_task_id=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 5, len test: 5\n"
     ]
    }
   ],
   "source": [
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True\n",
    ")\n",
    "train_stream = benchmark.train_stream\n",
    "test_stream = benchmark.test_stream\n",
    "\n",
    "print(f\"len train: {len(train_stream)}, len test: {len(test_stream)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) - T0, classes=[0, 6]\n",
      "(1) - T1, classes=[1, 3]\n",
      "(2) - T2, classes=[2, 5]\n",
      "(3) - T3, classes=[9, 4]\n",
      "(4) - T4, classes=[8, 7]\n"
     ]
    }
   ],
   "source": [
    "for exp in train_stream:\n",
    "    eid = exp.current_experience\n",
    "    curr_classes = exp.classes_in_this_experience\n",
    "    tid = exp.task_label\n",
    "    print(f\"({eid}) - T{tid}, classes={curr_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x, **kwargs):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "model = MLP()\n",
    "model(torch.randn(32, 784))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP is ignoring task_labels. You can use Avalanche MultiHeadClassifier to split the output layer by task id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.4492e-02, -1.4380e-02, -9.4812e-02,  1.0382e-01, -6.8324e-02,\n",
       "         -2.9779e-02, -6.6003e-03,  1.0679e-01, -3.6159e-04,  8.6781e-02],\n",
       "        [-6.0239e-02,  2.0708e-01, -6.8435e-02,  1.3024e-01, -8.3926e-02,\n",
       "          1.1956e-01,  9.2401e-02,  7.5060e-03,  7.6041e-02,  1.5360e-01],\n",
       "        [-4.3249e-02, -1.6782e-03,  1.8559e-02,  2.1451e-01,  1.9979e-02,\n",
       "          1.1966e-01,  3.8635e-03,  1.1762e-01,  9.6107e-02,  1.8521e-01],\n",
       "        [-4.0077e-02,  1.1503e-02, -1.1938e-01,  5.5516e-02, -8.8268e-02,\n",
       "          8.8493e-02,  6.3556e-02, -1.1909e-02,  7.1932e-02,  1.0055e-01],\n",
       "        [-9.6918e-02, -3.9918e-02, -4.4975e-02,  8.0528e-02, -6.5870e-02,\n",
       "          1.4336e-01,  3.1440e-02,  1.2471e-02,  9.2671e-02,  9.8498e-02],\n",
       "        [-2.3040e-02,  5.0516e-02, -9.0975e-02,  2.4542e-02,  1.5074e-03,\n",
       "          7.6702e-02,  1.5388e-01,  1.0248e-01,  2.0437e-01,  1.4489e-01],\n",
       "        [ 3.4005e-02, -4.0677e-02, -6.5232e-02,  4.5179e-02,  6.2408e-02,\n",
       "          6.8461e-02,  7.8795e-02, -5.9562e-02,  1.6349e-01,  8.3405e-02],\n",
       "        [ 6.1994e-02,  1.4610e-02, -1.3239e-01,  1.4963e-01, -1.5661e-02,\n",
       "          1.5060e-01, -6.2012e-03,  5.5802e-02,  1.0362e-01,  5.7304e-02],\n",
       "        [ 1.7478e-01, -4.0724e-02, -9.3582e-02, -6.4682e-02, -1.0465e-03,\n",
       "          3.1850e-02,  4.7147e-03, -1.0788e-01,  1.8623e-01, -6.3430e-02],\n",
       "        [ 2.4152e-02, -5.2628e-02, -1.2296e-01,  1.5805e-01, -6.1687e-02,\n",
       "          1.1516e-01, -7.5544e-02,  5.7154e-02,  5.5708e-02,  3.1743e-02],\n",
       "        [-3.4263e-02,  6.4302e-02, -7.1451e-02,  8.9327e-02, -1.7888e-02,\n",
       "          1.0203e-01,  3.5463e-02,  7.4671e-02,  1.4317e-01,  9.8445e-02],\n",
       "        [-1.4113e-01,  1.3344e-02, -1.7146e-01,  3.7274e-02, -7.4932e-02,\n",
       "         -1.6073e-03, -7.7600e-02,  1.2927e-01,  1.7799e-01,  6.5132e-02],\n",
       "        [ 3.0766e-02,  2.2626e-02, -3.2118e-02,  8.2883e-02, -1.8556e-02,\n",
       "          6.0717e-02,  6.3423e-02,  6.6687e-02,  5.3596e-03,  8.0409e-02],\n",
       "        [-8.2573e-02,  1.2252e-03, -8.8166e-02, -4.7606e-02, -6.6586e-02,\n",
       "          1.2635e-01,  1.0191e-01,  1.5327e-02,  1.3018e-01,  1.0707e-01],\n",
       "        [ 1.0334e-01,  1.5646e-01, -5.0762e-02,  4.6538e-03,  3.4464e-02,\n",
       "          1.1049e-01,  1.0894e-01, -2.2169e-02,  1.5317e-01,  8.9473e-02],\n",
       "        [ 4.8557e-02, -3.3685e-02, -5.3676e-02, -6.2058e-02, -7.8232e-02,\n",
       "          8.9361e-02,  8.0106e-02,  3.8470e-02,  2.0285e-01,  3.4082e-02],\n",
       "        [-2.4709e-02,  8.0774e-02, -7.8207e-02,  1.1697e-01,  3.5945e-02,\n",
       "          8.4341e-02,  1.4103e-01,  1.4794e-02,  1.5962e-01,  6.7180e-02],\n",
       "        [-6.5026e-02,  7.8620e-05, -2.2538e-01, -1.0434e-02,  1.7259e-02,\n",
       "          1.3588e-01,  9.5308e-02,  5.8421e-02,  2.1289e-01,  2.6393e-01],\n",
       "        [ 5.8676e-02,  4.3819e-02, -1.4002e-01,  7.5946e-02, -5.8477e-02,\n",
       "          5.0515e-02,  1.3426e-02,  6.7208e-02,  1.0749e-01,  1.8448e-01],\n",
       "        [-1.0605e-01,  5.9971e-02, -1.7879e-01,  1.2720e-01, -1.2029e-01,\n",
       "          4.0942e-03,  3.5974e-02,  1.2011e-01,  1.0512e-01,  1.9866e-02],\n",
       "        [-2.5800e-02,  1.9380e-01, -1.8495e-01,  1.0912e-01,  8.5693e-02,\n",
       "          1.6636e-01, -3.4904e-02,  2.3993e-02,  2.4396e-01,  8.1801e-02],\n",
       "        [ 2.6849e-02,  1.5349e-02, -8.0030e-02,  1.0442e-02,  1.9420e-02,\n",
       "          2.8919e-02, -4.9251e-02,  3.2208e-02,  1.9090e-01,  1.1288e-01],\n",
       "        [-4.2375e-02,  5.3474e-02, -4.3045e-02, -2.3716e-02, -8.7816e-02,\n",
       "          3.2771e-02,  5.1739e-02,  1.1287e-01,  1.0305e-01,  1.2147e-01],\n",
       "        [ 3.0908e-02,  8.0828e-02, -8.2367e-02, -1.2325e-02, -1.2867e-02,\n",
       "          6.6578e-02,  3.7607e-02, -5.9992e-02,  3.3876e-02,  7.4329e-02],\n",
       "        [-9.5645e-02, -2.6715e-02, -2.2346e-02,  1.1867e-01,  4.3171e-02,\n",
       "          4.8154e-02,  1.0034e-01,  1.4409e-01,  2.1093e-01,  7.8876e-02],\n",
       "        [-9.0513e-02, -5.8981e-02, -1.4851e-02,  1.3460e-01, -1.0278e-01,\n",
       "         -5.1424e-02,  6.1901e-02,  1.1495e-02,  7.3557e-02,  5.2098e-02],\n",
       "        [ 1.1919e-01,  2.8389e-02, -7.3419e-02, -1.3757e-01, -1.1185e-01,\n",
       "          1.4567e-01,  6.8519e-02,  5.2068e-02,  1.6561e-01, -1.1252e-02],\n",
       "        [-4.3468e-02,  1.2268e-01, -1.8620e-01,  4.0576e-02, -4.9551e-02,\n",
       "          3.8510e-02,  3.1270e-02, -5.5017e-02,  3.2389e-02,  5.1261e-02],\n",
       "        [-4.2945e-02, -6.9585e-03, -1.2381e-01, -3.7096e-02, -1.0590e-01,\n",
       "         -6.7322e-02,  2.6497e-02, -2.4759e-02,  1.1823e-01,  3.2280e-02],\n",
       "        [-2.3923e-02,  5.0272e-02, -5.5682e-02,  2.3554e-01,  3.0616e-02,\n",
       "          5.9319e-02, -3.7563e-02, -4.4135e-02,  7.4226e-02,  5.5170e-02],\n",
       "        [-7.8549e-03, -5.6372e-02, -1.4830e-01, -1.9422e-02,  1.2169e-01,\n",
       "          4.7368e-02,  2.4446e-02,  6.1426e-02,  1.1885e-01,  7.5860e-02],\n",
       "        [ 1.0605e-01,  6.5638e-02, -2.5814e-01,  9.3988e-02,  1.0332e-02,\n",
       "          6.8115e-02, -3.0561e-02,  4.8958e-02,  1.2754e-01,  7.0802e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 784)\n",
    "t = torch.randint(low=0, high=4, size=(32,))\n",
    "model(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskDecorator(\n",
      "  (model): MLP(\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): MultiHeadClassifier(\n",
      "    (classifiers): ModuleDict(\n",
      "      (0): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models import as_multitask\n",
    "\n",
    "model_mt = as_multitask(MLP(), 'classifier')\n",
    "print(model_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 2, 3, 1, 1, 2, 3, 1, 2, 1, 1, 1, 0, 1, 2, 0, 0, 3, 2, 0, 1, 1,\n",
       "        1, 3, 0, 3, 1, 0, 0, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still doesn't know about all the tasks because it has neven seen them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl03\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:156\u001b[0m, in \u001b[0;36mMultiTaskModule.forward\u001b[1;34m(self, x, task_labels)\u001b[0m\n\u001b[0;32m    154\u001b[0m task_mask \u001b[38;5;241m=\u001b[39m task_labels \u001b[38;5;241m==\u001b[39m task\n\u001b[0;32m    155\u001b[0m x_task \u001b[38;5;241m=\u001b[39m x[task_mask]\n\u001b[1;32m--> 156\u001b[0m out_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_task\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, (\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti-head assumes mini-batches of 2 dimensions \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<batch, classes>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m )\n\u001b[0;32m    161\u001b[0m n_labels_head \u001b[38;5;241m=\u001b[39m out_task\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl03\\lib\\site-packages\\avalanche\\models\\helper_method.py:74\u001b[0m, in \u001b[0;36mMultiTaskDecorator.forward_single_task\u001b[1;34m(self, x, task_label)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_single_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, task_label: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m     73\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_label\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl03\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl03\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:148\u001b[0m, in \u001b[0;36mMultiTaskModule.forward\u001b[1;34m(self, x, task_labels)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_all_tasks(x)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_labels, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# fast path. mini-batch is single task.\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    150\u001b[0m     unique_tasks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(task_labels)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl03\\lib\\site-packages\\avalanche\\models\\dynamic_modules.py:409\u001b[0m, in \u001b[0;36mMultiHeadClassifier.forward_single_task\u001b[1;34m(self, x, task_label)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"compute the output given the input `x`. This module uses the task\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;124;03mlabel to activate the correct head.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    408\u001b[0m task_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(task_label)\n\u001b[1;32m--> 409\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifiers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_label\u001b[49m\u001b[43m]\u001b[49m(x)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking:\n\u001b[0;32m    411\u001b[0m     au_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_units_T\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\avl03\\lib\\site-packages\\torch\\nn\\modules\\container.py:416\u001b[0m, in \u001b[0;36mModuleDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;129m@_copy_to_script_wrapper\u001b[39m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Module:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "model_mt(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to adapt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskDecorator(\n",
      "  (model): MLP(\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): MultiHeadClassifier(\n",
      "    (classifiers): ModuleDict(\n",
      "      (0): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (1): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (2): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (3): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "      (4): IncrementalClassifier(\n",
      "        (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "\n",
    "for exp in benchmark.train_stream:\n",
    "    avalanche_model_adaptation(model_mt, exp)\n",
    "\n",
    "print(model_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model has been adapted to all the tasks. A separate head for each task is available for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+03,  1.0238e-01, -1.0000e+03,  7.3385e-04, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -3.9755e-02, -1.0000e+03, -1.0000e+03,\n",
       "          8.0407e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03,  6.7919e-02, -1.0000e+03, -1.0000e+03,\n",
       "         -2.1614e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -2.8848e-02, -1.0000e+03, -1.0000e+03,\n",
       "          3.4406e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.4304e-01,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  3.4524e-02],\n",
       "        [-1.0000e+03,  2.4361e-02, -1.0000e+03, -1.2844e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03,  1.4934e-01, -1.0000e+03, -2.3455e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -5.6244e-02, -1.0000e+03, -1.0000e+03,\n",
       "          4.7768e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.8027e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0817e-01],\n",
       "        [-1.0000e+03,  2.3518e-02, -1.0000e+03,  6.6721e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -4.4569e-02, -1.0000e+03, -1.0000e+03,\n",
       "          2.4374e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0756e-01, -1.0000e+03, -1.0388e-01, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0482e-01, -1.0000e+03, -7.8134e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03,  1.1870e-01, -1.0000e+03, -3.3539e-03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-2.3955e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  3.4329e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0151e-01, -1.0000e+03, -1.0368e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -3.5201e-02, -1.0000e+03, -1.0000e+03,\n",
       "          3.1478e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 6.9514e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -2.3148e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 2.5755e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  1.1017e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.8007e-01,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  3.1048e-02],\n",
       "        [-1.0000e+03, -1.0000e+03,  4.9872e-02, -1.0000e+03, -1.0000e+03,\n",
       "          8.4968e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-6.9233e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03,  1.4709e-03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03,  2.7199e-02, -1.0000e+03, -1.4013e-01, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.2564e-02, -1.0000e+03, -1.6644e-01, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03,  8.1800e-02, -1.0000e+03,  1.8582e-03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.7180e-01,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,  1.1794e-02],\n",
       "        [-1.2556e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.2477e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -2.6354e-02,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -2.9460e-02],\n",
       "        [-1.0000e+03, -3.1289e-02, -1.0000e+03, -5.5355e-02, -1.0000e+03,\n",
       "         -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [ 6.3336e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -3.8626e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-9.0941e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03,\n",
       "         -1.0000e+03, -1.2525e-01, -1.0000e+03, -1.0000e+03, -1.0000e+03],\n",
       "        [-1.0000e+03, -1.0000e+03, -6.2751e-02, -1.0000e+03, -1.0000e+03,\n",
       "         -4.0607e-02, -1.0000e+03, -1.0000e+03, -1.0000e+03, -1.0000e+03]],\n",
       "       grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mt(x, task_labels=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training loop - Finetuning (with Multi-head model)\n",
    "\n",
    "We can train the model continually by iterating over the `train_stream` provided by the scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.training import Naive\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# scenario\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# model\n",
    "model = as_multitask(MLP(), 'classifier')\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience (0)\n",
      "Train Epoch: 0 \tLoss: 0.219103\n",
      "Train Epoch: 1 \tLoss: 0.205423\n",
      "Experience (1)\n",
      "Train Epoch: 0 \tLoss: 0.100193\n",
      "Train Epoch: 1 \tLoss: 0.044830\n",
      "Experience (2)\n",
      "Train Epoch: 0 \tLoss: 0.089650\n",
      "Train Epoch: 1 \tLoss: 0.037385\n",
      "Experience (3)\n",
      "Train Epoch: 0 \tLoss: 0.077952\n",
      "Train Epoch: 1 \tLoss: 0.032585\n",
      "Experience (4)\n",
      "Train Epoch: 0 \tLoss: 0.099708\n",
      "Train Epoch: 1 \tLoss: 0.101100\n"
     ]
    }
   ],
   "source": [
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "from avalanche.models.dynamic_optimizers import reset_optimizer\n",
    "\n",
    "device = 'cpu'\n",
    "num_epochs = 2\n",
    "\n",
    "for exp in benchmark.train_stream:\n",
    "    print(f\"Experience ({exp.current_experience})\")\n",
    "    model.train()\n",
    "\n",
    "    # AVALANCHE: model adaptation step adds new parameters\n",
    "    # In our model: adds a new head for each task\n",
    "    avalanche_model_adaptation(model, exp)\n",
    "    # AVALANCHE: We just added parameters to the model. We must also update the optimizer\n",
    "    reset_optimizer(optimizer, model)\n",
    "    \n",
    "    dataset = exp.dataset\n",
    "    dataset = dataset.train()  # AVALANCHE: activate correct transformation group\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        dl = DataLoader(dataset, batch_size=128)\n",
    "        for x, y, t in dl:\n",
    "          x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          # AVALANCHE: MultiTaskModels need task labels\n",
    "          output = model(x, t)\n",
    "          loss = F.cross_entropy(output, y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Replay Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# scenario\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=True,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# model\n",
    "model = as_multitask(MLP(), 'classifier')\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max buffer size: 30, current size: 0\n",
      "Max buffer size: 30, current size: 0\n",
      "Experience (0)\n",
      "Train Epoch: 0 \tLoss: 0.219103\n",
      "Train Epoch: 1 \tLoss: 0.205423\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "\n",
      "Experience (1)\n",
      "Train Epoch: 0 \tLoss: 0.097878\n",
      "Train Epoch: 1 \tLoss: 0.042620\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "Experience (2)\n",
      "Train Epoch: 0 \tLoss: 0.107203\n",
      "Train Epoch: 1 \tLoss: 0.046786\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8]\n",
      "\n",
      "Experience (3)\n",
      "Train Epoch: 0 \tLoss: 0.079960\n",
      "Train Epoch: 1 \tLoss: 0.032946\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 5, 6, 6, 6, 6, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 8, 8, 8, 9, 9, 9, 3, 3, 3, 3]\n",
      "\n",
      "Experience (4)\n",
      "Train Epoch: 0 \tLoss: 0.108208\n",
      "Train Epoch: 1 \tLoss: 0.102472\n",
      "Max buffer size: 30, current size: 30\n",
      "class targets: [5, 5, 5, 6, 6, 6, 1, 1, 1, 2, 2, 2, 0, 0, 0, 8, 8, 8, 9, 9, 9, 3, 3, 3, 4, 4, 4, 7, 7, 7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
    "\n",
    "device = 'cpu'\n",
    "num_epochs = 2\n",
    "\n",
    "# AVALANCHE: init replay buffer\n",
    "storage_p = ParametricBuffer(\n",
    "    max_size=30,\n",
    "    groupby='class',\n",
    "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
    ")\n",
    "\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")   \n",
    "for exp in benchmark.train_stream:\n",
    "    print(f\"Experience ({exp.current_experience})\")\n",
    "    model.train()\n",
    "    avalanche_model_adaptation(model, exp)\n",
    "    reset_optimizer(optimizer, model)\n",
    "    dataset = exp.dataset\n",
    "    dataset = dataset.train()\n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        # AVALANCHE: ReplayDataLoader to sample jointly from buffer and current data.\n",
    "        dl = ReplayDataLoader(dataset, storage_p.buffer, batch_size=128)\n",
    "        for x, y, t in dl:\n",
    "          x, y, t = x.to(device), y.to(device), t.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          output = model(x, t)\n",
    "          loss = F.cross_entropy(output, y)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
    "    \n",
    "    # AVALANCHE: you can use a SimpleNamespace if you want to use Avalanche components with your own code.\n",
    "    strategy_state = SimpleNamespace(experience=exp)\n",
    "    # AVALANCHE: update replay buffer\n",
    "    storage_p.update(strategy_state)\n",
    "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
    "    print(f\"class targets: {list(storage_p.buffer.targets)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
